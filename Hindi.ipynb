{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ac7b3c-a24c-4ba3-a37f-c327cdff0345",
      "metadata": {
        "id": "a2ac7b3c-a24c-4ba3-a37f-c327cdff0345"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3e0b65-d8b8-4bf6-8d75-e162ec567841",
      "metadata": {
        "id": "bf3e0b65-d8b8-4bf6-8d75-e162ec567841"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part1 Transformers for Sequence Classification"
      ],
      "metadata": {
        "id": "uiLPhMg-55LQ"
      },
      "id": "uiLPhMg-55LQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0276fa0c-8080-4d45-903a-1f1aa2d88168",
      "metadata": {
        "id": "0276fa0c-8080-4d45-903a-1f1aa2d88168"
      },
      "outputs": [],
      "source": [
        "# savind the model and datasetname as constants\n",
        "MODEL_ENGLISH=\"distilbert-base-uncased\"\n",
        "DATASET_ENGLISH=\"wnut_17\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f516401d-ba81-4feb-aae9-f6102dc8b1e9",
      "metadata": {
        "id": "f516401d-ba81-4feb-aae9-f6102dc8b1e9"
      },
      "outputs": [],
      "source": [
        "#Load the dataset\n",
        "english_dataset=load_dataset(DATASET_ENGLISH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c8a546-3894-4867-bd4a-b88ccfe1a32b",
      "metadata": {
        "id": "82c8a546-3894-4867-bd4a-b88ccfe1a32b"
      },
      "outputs": [],
      "source": [
        "#ImportModel\n",
        "tokenizer=AutoTokenizer.from_pretrained(MODEL_ENGLISH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c26964-5379-4248-9c89-dc4fdb90d116",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "43b367a5e14140c681f3926e47a8b63b"
          ]
        },
        "id": "d0c26964-5379-4248-9c89-dc4fdb90d116",
        "outputId": "b4b41afc-3b28-485e-9399-b45f914278c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43b367a5e14140c681f3926e47a8b63b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1287 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Code taken from the tutorial\n",
        "def preprocessing(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "tokenized_ds = english_dataset.map(preprocessing, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4423dfe3-9f69-4671-bca4-fc94906181de",
      "metadata": {
        "id": "4423dfe3-9f69-4671-bca4-fc94906181de"
      },
      "outputs": [],
      "source": [
        "data_collator=DataCollatorForTokenClassification(tokenizer=tokenizer) # Code taken from the tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ac8dd8-7b07-41d4-af4c-dd713b5c2a5a",
      "metadata": {
        "id": "66ac8dd8-7b07-41d4-af4c-dd713b5c2a5a"
      },
      "outputs": [],
      "source": [
        "seqeval = evaluate.load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e0740fd-c3a8-4087-acfe-d39419987b3f",
      "metadata": {
        "id": "8e0740fd-c3a8-4087-acfe-d39419987b3f",
        "outputId": "8b49eab6-519b-4b07-fede-4603745eadc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'O', 1: 'B-corporation', 2: 'I-corporation', 3: 'B-creative-work', 4: 'I-creative-work', 5: 'B-group', 6: 'I-group', 7: 'B-location', 8: 'I-location', 9: 'B-person', 10: 'I-person', 11: 'B-product', 12: 'I-product'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "label_list = english_dataset[\"train\"].features[f\"ner_tags\"].feature.names\n",
        "\n",
        "#Use a dictionary comprehension to create the maps\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6593b28-e49d-4484-b7e8-a44b36f9f9e4",
      "metadata": {
        "id": "d6593b28-e49d-4484-b7e8-a44b36f9f9e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=13, id2label=id2label, label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d894d1-5c6d-4b3b-b3af-24a709476009",
      "metadata": {
        "id": "a6d894d1-5c6d-4b3b-b3af-24a709476009"
      },
      "outputs": [],
      "source": [
        "# Code chunk taken from the tutorial\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "385f2ad5-fb1e-466c-ae8b-8a4c6cabd0fa",
      "metadata": {
        "id": "385f2ad5-fb1e-466c-ae8b-8a4c6cabd0fa",
        "outputId": "d8003c6f-02f8-4e27-e511-7deffe4efef1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib64/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 03:14, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.294205</td>\n",
              "      <td>0.411439</td>\n",
              "      <td>0.206673</td>\n",
              "      <td>0.275139</td>\n",
              "      <td>0.935787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.273170</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.301205</td>\n",
              "      <td>0.399018</td>\n",
              "      <td>0.940960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.270342</td>\n",
              "      <td>0.558214</td>\n",
              "      <td>0.324374</td>\n",
              "      <td>0.410317</td>\n",
              "      <td>0.943141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.272618</td>\n",
              "      <td>0.523055</td>\n",
              "      <td>0.336423</td>\n",
              "      <td>0.409475</td>\n",
              "      <td>0.943440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.266524</td>\n",
              "      <td>0.508108</td>\n",
              "      <td>0.348471</td>\n",
              "      <td>0.413414</td>\n",
              "      <td>0.944167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gusmatacal@GU.GU.SE/.local/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib64/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/usr/local/lib64/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/usr/local/lib64/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/usr/local/lib64/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/usr/local/lib64/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=270, training_loss=0.11503364421703198, metrics={'train_runtime': 194.7263, 'train_samples_per_second': 87.148, 'train_steps_per_second': 1.387, 'total_flos': 259035045125820.0, 'train_loss': 0.11503364421703198, 'epoch': 5.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Code chunk taken from tutorial\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"English_Model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 Using BERT with Our Data"
      ],
      "metadata": {
        "id": "uliz5YM66HWA"
      },
      "id": "uliz5YM66HWA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e09e962-9a99-4047-b0ec-16c56876fa55",
      "metadata": {
        "id": "6e09e962-9a99-4047-b0ec-16c56876fa55"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "# Root to the data\n",
        "ROOT = pathlib.Path(\"/srv/data/lt2326-h25/a2\")\n",
        "ROOT.exists()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee55ed46-ead3-4b7b-b376-df19355b80eb",
      "metadata": {
        "id": "ee55ed46-ead3-4b7b-b376-df19355b80eb"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "train_file = Path(\"/srv/data/lt2326-h25/a2/hi_hdtb-ud-train.conllu\")\n",
        "\n",
        "with train_file.open(encoding=\"utf-8\") as f:\n",
        "    for i in range(30):\n",
        "        print(f.readline().rstrip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee6c3c1-2a64-468c-8bb5-7b55d6c56c5b",
      "metadata": {
        "id": "6ee6c3c1-2a64-468c-8bb5-7b55d6c56c5b"
      },
      "outputs": [],
      "source": [
        "#Define path to the splits\n",
        "TRAIN_PATH = Path(\"/srv/data/lt2326-h25/a2/hi_hdtb-ud-train.conllu\")\n",
        "DEV_PATH   = Path(\"/srv/data/lt2326-h25/a2/hi_hdtb-ud-dev.conllu\")\n",
        "TEST_PATH  = Path(\"/srv/data/lt2326-h25/a2/hi_hdtb-ud-test.conllu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering that the data came in the CONLLU format and that Transfomer models require the data to be in a certain format, after defining the paths to the dataset, I created a function that goes through each sentence in the dataset (considered that if there is a line or a comment, then it is a new sentence), and collect the tokens and add them to a list (sentences), collect the MISC Field which contains ChunkId, which indicates the semantic group the token belongs to. Additionally, since the dataset does not explicitly have IOB labels, I had to generate them based on the ChunkID, as follows: O if the ChunkID is “O”, I if the ChunkID matches the previous one, hence being part of the same entity, and B if the ChunkID does not match the previous one, being part of a different entity.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zNtvb9BQ6lY-"
      },
      "id": "zNtvb9BQ6lY-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a09d8a2-2f36-4d3b-b4a0-750a5e44f0b0",
      "metadata": {
        "id": "4a09d8a2-2f36-4d3b-b4a0-750a5e44f0b0"
      },
      "outputs": [],
      "source": [
        "def read_conllu_iob(path):\n",
        "    #Initialize containers for sentences and their token-level IOB labels.\n",
        "    sentences, iob_labels = [], []\n",
        "    tokens, labels = [], []\n",
        "    prev_chunk_id = None\n",
        "\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            #If blank line or comment consider it a new sentence\n",
        "            if not line or line.startswith(\"#\"):\n",
        "                if tokens:\n",
        "                    sentences.append(tokens)\n",
        "                    iob_labels.append(labels)\n",
        "                    tokens, labels, prev_chunk_id = [], [], None\n",
        "                continue\n",
        "\n",
        "            cols = line.split(\"\\t\")\n",
        "            if len(cols) < 10:\n",
        "                continue\n",
        "\n",
        "            token = cols[1]\n",
        "            misc = cols[9]\n",
        "            #Extract ChunkId, which identifies which chunk the token belongs to.\n",
        "            curr_chunk_id = \"O\"\n",
        "            if misc != \"_\":\n",
        "                misc_data = dict(\n",
        "                    item.split(\"=\") for item in misc.split(\"|\") if \"=\" in item\n",
        "                )\n",
        "                curr_chunk_id = misc_data.get(\"ChunkId\", \"O\")\n",
        "            # Reconstruct IOB tags based on transitions between ChunkIds.\n",
        "            if curr_chunk_id == \"O\":\n",
        "                iob_label = \"O\"\n",
        "            elif curr_chunk_id != prev_chunk_id:\n",
        "                iob_label = f\"B-{curr_chunk_id}\"\n",
        "            else:\n",
        "                iob_label = f\"I-{curr_chunk_id}\"\n",
        "\n",
        "            tokens.append(token)\n",
        "            labels.append(iob_label)\n",
        "            prev_chunk_id = curr_chunk_id\n",
        "\n",
        "    # catch last sentence\n",
        "    if tokens:\n",
        "        sentences.append(tokens)\n",
        "        iob_labels.append(labels)\n",
        "\n",
        "    return sentences, iob_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fee94e5-94c9-49e4-881b-1a4705ab3666",
      "metadata": {
        "id": "1fee94e5-94c9-49e4-881b-1a4705ab3666"
      },
      "outputs": [],
      "source": [
        "#transofrm all splits\n",
        "train_sentences, train_labels = read_conllu_iob(TRAIN_PATH)\n",
        "dev_sentences, dev_labels     = read_conllu_iob(DEV_PATH)\n",
        "test_sentences, test_labels   = read_conllu_iob(TEST_PATH)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subsequently, I transformed the labels from strings to integers, and align the tokens and labels, similar to how is done in the tutorial. I did take the labels from all splits, as when I was trying to load the models, there were labels that were found in the dev set, but not in the train set. Aditionally I transfomred the data in order to be able to use the Dataset class from huggingface.\n"
      ],
      "metadata": {
        "id": "9QNpZlKd6hQQ"
      },
      "id": "9QNpZlKd6hQQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3f0d0e-d9f4-4299-8c04-2aa8e297f285",
      "metadata": {
        "id": "cb3f0d0e-d9f4-4299-8c04-2aa8e297f285"
      },
      "outputs": [],
      "source": [
        "#Transform labels from string to int\n",
        "all_labels = (\n",
        "    train_labels\n",
        "    + dev_labels\n",
        "    + test_labels\n",
        ")\n",
        "\n",
        "label_list = sorted(set(l for sent in all_labels for l in sent))\n",
        "label2id = {l: i for i, l in enumerate(label_list)}\n",
        "id2label = {i: l for l, i in label2id.items()}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def make_dataset(sentences, labels, tokenizer):\n",
        "    encodings = tokenizer(\n",
        "        sentences,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "    )\n",
        "\n",
        "    aligned_labels = []\n",
        "    for i, label_seq in enumerate(labels):\n",
        "        word_ids = encodings.word_ids(batch_index=i)\n",
        "        prev = None\n",
        "        label_ids = []\n",
        "\n",
        "        for w in word_ids:\n",
        "            if w is None:\n",
        "                label_ids.append(-100)\n",
        "            elif w != prev:\n",
        "                label_ids.append(label2id[label_seq[w]])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            prev = w\n",
        "\n",
        "        # ✅ this must be OUTSIDE the inner loop\n",
        "        aligned_labels.append(label_ids)\n",
        "\n",
        "    encodings[\"labels\"] =\n"
      ],
      "metadata": {
        "id": "kKLUYVyd-8p7"
      },
      "id": "kKLUYVyd-8p7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction metrics for hindi"
      ],
      "metadata": {
        "id": "xFQtvR6d-wSg"
      },
      "id": "xFQtvR6d-wSg"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics_hindi(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, lab) if l != -100]\n",
        "        for pred, lab in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(\n",
        "        predictions=true_predictions,\n",
        "        references=true_labels\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n"
      ],
      "metadata": {
        "id": "2DoEJKpN-t2p"
      },
      "id": "2DoEJKpN-t2p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1st Model\n",
        "\n",
        "When it was about training the model, I did encounter a big problem, that of running out of GPU since  I wanted to work with ROBERTa Hindi. Hence I decided to go with a relatively smaller models, both distilbert, one being a [md-nishat-008 Mixed-Distil-BERT](https://huggingface.co/md-nishat-008/Mixed-Distil-BERT), which I decided to use since its trained on a good amount of data, 560k, however, the data it is a code-mixed of english-hindi-bengali.  \n"
      ],
      "metadata": {
        "id": "FXVNTqVE68jF"
      },
      "id": "FXVNTqVE68jF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "762444fa-de71-420b-bbd4-d3aa6d08f016",
      "metadata": {
        "id": "762444fa-de71-420b-bbd4-d3aa6d08f016",
        "outputId": "53cb9a12-0a57-4c2d-f6b0-a8e92064f7c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at md-nishat-008/Mixed-Distil-BERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"md-nishat-008/Mixed-Distil-BERT\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_dataset = make_dataset(train_sentences, train_labels, tokenizer)\n",
        "dev_dataset   = make_dataset(dev_sentences, dev_labels, tokenizer)\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(label_list), # Classification head\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1047f141-8d3d-4b5c-bd62-f6971751912a",
      "metadata": {
        "id": "1047f141-8d3d-4b5c-bd62-f6971751912a"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec003d30-811d-44b0-811b-8031234e998e",
      "metadata": {
        "id": "ec003d30-811d-44b0-811b-8031234e998e"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "#Decided to go with only 2 epoch due to the GPU issues\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./mixed-distilbert-hindi\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=50,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_hindi,\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd Model\n",
        "For the second Model I went with  [distilbert-base-multilingual-cased](https://huggingface.co/distilbert/distilbert-base-multilingual-cased) as it is a fairly used model, trained on multiple languages, and on bigger amount of data. I believe it is a good model for comparasion"
      ],
      "metadata": {
        "id": "8eV50Y4C71NE"
      },
      "id": "8eV50Y4C71NE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acd4c728-2ade-4647-9506-cd92ac2ca467",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1b0ebbe9ec704024ab5440367df2f818",
            "99c103365c494bfda264c3ef23f63f3e",
            "a996ca63f525475984b616cbaa23c54a",
            "3c640a1f2552418f841109bf7888d79c"
          ]
        },
        "id": "acd4c728-2ade-4647-9506-cd92ac2ca467",
        "outputId": "a99f57fc-e603-4409-e5c6-783a6f8aff5e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b0ebbe9ec704024ab5440367df2f818",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99c103365c494bfda264c3ef23f63f3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a996ca63f525475984b616cbaa23c54a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c640a1f2552418f841109bf7888d79c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME_2 = \"distilbert-base-multilingual-cased\"\n",
        "\n",
        "tokenizer_2 = AutoTokenizer.from_pretrained(MODEL_NAME_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e616599-96e9-424e-b07b-c931bc0cedb5",
      "metadata": {
        "id": "7e616599-96e9-424e-b07b-c931bc0cedb5"
      },
      "outputs": [],
      "source": [
        "train_dataset_2 = make_dataset(train_sentences, train_labels, tokenizer_2)\n",
        "dev_dataset_2   = make_dataset(dev_sentences, dev_labels, tokenizer_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96fcd06a-37c8-4b12-89f9-ff4f0c507a47",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "28f3a24c25704e72a92b31dd6dc76697"
          ]
        },
        "id": "96fcd06a-37c8-4b12-89f9-ff4f0c507a47",
        "outputId": "c5523f0e-3b5d-49be-d1ab-8aae1e2bf42c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28f3a24c25704e72a92b31dd6dc76697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_2 = AutoModelForTokenClassification.from_pretrained(\n",
        "    MODEL_NAME_2,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c48ddc9-f729-4c23-a108-33a8ef9750f0",
      "metadata": {
        "id": "9c48ddc9-f729-4c23-a108-33a8ef9750f0"
      },
      "outputs": [],
      "source": [
        "training_args_2 = TrainingArguments(\n",
        "    output_dir=\"./distilbert-multilingual-hindi\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=50,\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a915423-ca3c-4268-9376-01306374c819",
      "metadata": {
        "id": "7a915423-ca3c-4268-9376-01306374c819"
      },
      "outputs": [],
      "source": [
        "trainer_2 = Trainer(\n",
        "    model=model_2,\n",
        "    args=training_args_2,\n",
        "    train_dataset=train_dataset_2,\n",
        "    eval_dataset=dev_dataset_2,\n",
        "    tokenizer=tokenizer_2,\n",
        "    data_collator=DataCollatorForTokenClassification(tokenizer_2),\n",
        "    compute_metrics=compute_metrics_hindi,\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465d6b5b-fa32-4953-a0bf-9219c7481025",
      "metadata": {
        "id": "465d6b5b-fa32-4953-a0bf-9219c7481025"
      },
      "outputs": [],
      "source": [
        "trainer_2.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3\n",
        "Looking at both models from paer one we can see that second model performed better than the first model in all metrics. However that does not come as a suprise, firstly, because as mentioned the first model is trained on code-mixed language, and we do not know exactly how much percentage was actually hindi, compared with the second model that is trained on way more data, and its trained on wikipedia data, where hindi it is quite used."
      ],
      "metadata": {
        "id": "gIsYrzLz8cva"
      },
      "id": "gIsYrzLz8cva"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd0aeec-8557-49ba-aa76-471a1a092584",
      "metadata": {
        "id": "5fd0aeec-8557-49ba-aa76-471a1a092584"
      },
      "outputs": [],
      "source": [
        "test_dataset = make_dataset(test_sentences, test_labels, tokenizer)\n",
        "test_dataset_2 = make_dataset(test_sentences, test_labels, tokenizer_2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results_model_1 = trainer.evaluate(test_dataset)\n",
        "test_results_model_2 = trainer_2.evaluate(test_dataset_2)\n",
        "\n",
        "print(\"Model1:\", test_results_model_1)\n",
        "print(\"Model2:\", test_results_model_2)"
      ],
      "metadata": {
        "id": "JXfctngBDHlT"
      },
      "id": "JXfctngBDHlT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}